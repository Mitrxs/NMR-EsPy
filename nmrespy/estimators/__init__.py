# __init__.py
# Simon Hulse
# simon.hulse@chem.ox.ac.uk
# Last Edited: Thu 29 Sep 2022 11:50:32 BST

from __future__ import annotations
import abc
import datetime
import functools
from pathlib import Path
from typing import Any, Dict, Iterable, Optional, Tuple, Union

import matplotlib as mpl
import numpy as np

import nmrespy as ne
from nmrespy._colors import RED, GRE, END, USE_COLORAMA
from nmrespy._files import (
    check_saveable_path,
    check_existent_path,
    configure_path,
    open_file,
    save_file,
)
from nmrespy._result_fetcher import ResultFetcher
from nmrespy._sanity import sanity_check, funcs as sfuncs
from nmrespy import sig
from nmrespy.freqfilter import Filter
from nmrespy.mpm import MatrixPencil
from nmrespy.nlp import NonlinearProgramming
from nmrespy.write import ResultWriter
from nmrespy.write.textfile import experiment_info, titled_table

if USE_COLORAMA:
    import colorama
    colorama.init()


def logger(f: callable):
    @functools.wraps(f)
    def inner(*args, **kwargs):
        class_instance = args[0]
        if "_log" in kwargs:
            if not kwargs["_log"]:
                return f(*args, **kwargs)
            else:
                del kwargs["_log"]
        class_instance._log += f"--> `{f.__name__}` {args[1:]} {kwargs}\n"
        return f(*args, **kwargs)
    return inner


class Estimator(ne.ExpInfo, metaclass=abc.ABCMeta):
    """Base estimation class."""

    matlab_available = ne.MATLAB_AVAILABLE

    def __init__(
        self,
        data: np.ndarray,
        expinfo: ne.ExpInfo,
        datapath: Optional[Path] = None,
    ) -> None:
        """Initialise a class instance.

        Parameters
        ----------
        data
            The data associated with the binary file in `path`.

        datapath
            The path to the directory containing the NMR data.

        expinfo
            Experiment information.
        """
        self._data = data
        self._datapath = datapath
        if hasattr(expinfo, "parameters"):
            self._bruker_params = expinfo.parameters

        super().__init__(
            dim=expinfo.dim,
            sw=expinfo.sw(),
            offset=expinfo.offset(),
            sfo=expinfo.sfo,
            nuclei=expinfo.nuclei,
            default_pts=expinfo.default_pts,
            fn_mode=expinfo.fn_mode,
        )

        self._results = []
        now = datetime.datetime.now().strftime('%d-%m-%y %H:%M:%S')
        self._log = (
            "=====================\n"
            "Logfile for Estimator\n"
            "=====================\n"
            f"--> Created @ {now}\n"
        )

    def __str__(self) -> str:
        writer = ResultWriter(
            self.expinfo,
            [params for params in self.get_params(merge=False)]
            if self._results else None,
            [errors for errors in self.get_errors(merge=False)]
            if self._results else None,
            None,
        )
        acqu_table = experiment_info(writer._construct_experiment_info(sig_figs=5))
        if self._results:
            titles = [
                f"{r.region[0][0]:.2f} - {r.region[0][1]:.2f}Hz"
                if r.region is not None else "Full signal"
                for r in self.get_results()
            ]
            param_tables = "\n\n" + "\n\n".join([
                titled_table(title, params) for title, params in zip(
                    titles,
                    writer._construct_parameters(
                        sig_figs=5, sci_lims=(-2, 3), integral_mode="relative",
                    )
                )
            ])
        else:
            param_tables = "\n\nNo estimation performed yet."

        return (
            f"<{self.__class__.__name__} object at {hex(id(self))}>\n\n"
            f"{acqu_table}{param_tables}"
        )

    def _check_results_exist(self) -> None:
        if not self._results:
            raise ValueError(f"{RED}No estimation has been carried out yet!{END}")

    @property
    def bruker_params(self) -> Optional[dict]:
        """Return a dictionary of Bruker parameters.

        If the class instance was generated by :py:meth:`new_bruker`, a
        dictionary of experiment parameters will be returned. Otherwise,
        ``None`` will be returned.
        """
        if hasattr(self, "_bruker_params"):
            return self._bruker_params
        else:
            return None

    @property
    def expinfo(self) -> ne.ExpInfo:
        return ne.ExpInfo(
            self.dim,
            self.sw(),
            self.offset(),
            self.sfo,
            self.nuclei,
            self.default_pts,
            self.fn_mode,
        )

    @property
    def data(self) -> np.ndarray:
        """Return the data associated with the estimator."""
        return self._data

    def get_log(self) -> str:
        """Get the log for the estimator instance."""
        return self._log

    def save_log(
        self,
        path: Union[str, Path] = "./espy_logfile",
        force_overwrite: bool = False,
        fprint: bool = True,
    ) -> None:
        """Save the estimator's log.

        Parameters
        ----------
        path
            The path to save the log to.

        force_overwrite
            If ``path`` already exists, ``force_overwrite`` set to ``True`` will get
            the user to confirm whether they are happy to overwrite the file.
            If ``False``, the file will be overwritten without prompt.

        fprint
            Specifies whether or not to print infomation to the terminal.
        """
        sanity_check(
            ("force_overwrite", force_overwrite, sfuncs.check_bool),
            ("fprint", fprint, sfuncs.check_bool),
        )
        sanity_check(
            ("path", path, check_saveable_path, ("log", force_overwrite)),
        )

        path = configure_path(path, "log")
        save_file(self.get_log(), path, fprint=fprint)

    @classmethod
    @abc.abstractmethod
    def new_bruker(*args, **kwargs):
        pass

    @abc.abstractmethod
    def view_data(*args, **kwargs):
        pass

    @logger
    def to_pickle(
        self,
        path: Optional[Union[Path, str]] = None,
        force_overwrite: bool = False,
        fprint: bool = True,
    ) -> None:
        """Save the estimator to a byte stream using Python's pickling protocol.

        Parameters
        ----------
        path
            Path of file to save the byte stream to. `'.pkl'` is added to the end of
            the path if this is not given by the user. If ``None``,
            ``./estimator_<x>.pkl`` will be used, where ``<x>`` is the first number
            that doesn't cause a clash with an already existent file.

        force_overwrite
            Defines behaviour if the specified path already exists:

            * If ``force_overwrite`` is set to ``False``, the user will be prompted
              if they are happy overwriting the current file.
            * If ``force_overwrite`` is set to ``True``, the current file will be
              overwritten without prompt.

        fprint
            Specifies whether or not to print infomation to the terminal.

        See Also
        --------

        :py:meth:`Estimator.from_pickle`
        """
        sanity_check(
            ("force_overwrite", force_overwrite, sfuncs.check_bool),
            ("fprint", fprint, sfuncs.check_bool),
        )
        sanity_check(
            ("path", path, check_saveable_path, ("pkl", force_overwrite), {}, True),
        )

        if path is None:
            x = 1
            while True:
                path = Path(f"estimator_{x}.pkl").resolve()
                if path.is_file():
                    x += 1
                else:
                    break

        path = configure_path(path, "pkl")
        save_file(self, path, binary=True, fprint=fprint)

    @classmethod
    def from_pickle(
        cls,
        path: Union[str, Path],
    ) -> Estimator:
        """Load a pickled estimator instance.

        Parameters
        ----------
        path
            The path to the pickle file.

        Returns
        -------
        estimator : :py:class:`Estimator`

        Notes
        -----
        .. warning::
           `From the Python docs:`

           *"The pickle module is not secure. Only unpickle data you trust.
           It is possible to construct malicious pickle data which will
           execute arbitrary code during unpickling. Never unpickle data
           that could have come from an untrusted source, or that could have
           been tampered with."*

           You should only use :py:meth:`from_pickle` on files that
           you are 100% certain were generated using
           :py:meth:`to_pickle`. If you load pickled data from a .pkl file,
           and the resulting output is not an instance of
           :py:class:`Estimator`, an error will be raised.

        See Also
        --------

        :py:meth:`Estimator.to_pickle`
        """
        sanity_check(("path", path, check_existent_path, ("pkl",)))
        path = configure_path(path, "pkl")
        obj = open_file(path, binary=True)

        if isinstance(obj, __class__):
            return obj
        else:
            raise TypeError(
                f"{RED}It is expected that the object loaded by"
                " `from_pickle` is an instance of"
                f" {__class__.__module__}.{__class__.__qualname__}."
                f" What was loaded didn't satisfy this!{END}"
            )

    def make_fid_from_result(
        self,
        indices: Optional[Iterable[int]],
        osc_indices: Optional[Iterable[Iterable[int]]] = None,
        pts: Optional[Iterable[int]] = None,
        indirect_modulation: Optional[str] = None,
    ):
        sanity_check(
            self._indices_check(indices),
            self._pts_check(pts),
        )

        indices = self._process_indices(indices)

        full_params = self.get_params(indices)
        sanity_check(
            (
                "osc_indices", osc_indices, sfuncs.check_int_list, (),
                {
                    "len_one_can_be_listless": True,
                    "min_value": 0,
                    "max_value": full_params.shape[0] - 1,
                },
                True,
            ),
        )

        if osc_indices is None:
            osc_indices = list(range(full_params.shape[0]))
        elif isinstance(osc_indices, int):
            osc_indices = [osc_indices]
        else:
            osc_indices = list(osc_indices)

        if self.dim > 1:
            sanity_check(
                (
                    "indirect_modulation", indirect_modulation,
                    sfuncs.check_one_of, ("amp", "phase"), {}, True
                ),
            )

        params = full_params[osc_indices]
        return self.make_fid(params, pts, indirect_modulation=indirect_modulation)

    @abc.abstractmethod
    def estimate(*args, **kwargs):
        pass

    def get_results(self, indices: Optional[Iterable[int]] = None) -> Iterable[Result]:
        """Obtain a subset of the estimation results obtained.

        By default, all results are returned, in the order in which they are obtained.

        Parameters
        ----------
        indices
            The indices of results to return. Index ``0`` corresponds to the first
            result obtained using the estimator, ``1`` corresponds to the next, etc.
            If ``None``, all results will be returned.
        """
        self._check_results_exist()
        sanity_check(
            self._indices_check(indices),
        )
        indices = self._process_indices(indices)
        return [self._results[i] for i in indices]

    def get_params(
        self,
        indices: Optional[Iterable[int]] = None,
        merge: bool = True,
        funit: str = "hz",
        sort_by: str = "f-1",
    ) -> Optional[Union[Iterable[np.ndarray], np.ndarray]]:
        """Return estimation result parameters.

        Parameters
        ----------
        indices
            The indices of results to extract parameters from. Index ``0``
            corresponds to the first result obtained using the estimator, ``1``
            corresponds to the next, etc.  If ``None``, all results will be
            used.

        merge
            If ``True``, a single array of all parameters from each specified
            estiamtion result specified will be returned. If ``False``, an iterable
            of each individual estimation result's parameters will be returned.

        funit
            The unit to express frequencies in. Must be one of ``"hz"`` and ``"ppm"``.

        sort_by
            Specifies the parameter by which the oscillators are ordered by.
            Should be one of ``"a"`` for amplitudes ``"p"`` for phase, ``"f<n>"``
            for frequency in the ``<n>``-th dimension, ``"d<n>"`` for the damping
            factor in the ``<n>``-th dimension. By setting ``<n>`` to ``-1``, the
            final (direct) dimension will be used. For 1D data, ``"f"`` and ``"d"``
            can be used to specify the frequency or damping factor.
        """
        self._check_results_exist()
        sanity_check(
            self._indices_check(indices),
            ("merge", merge, sfuncs.check_bool),
            ("funit", funit, sfuncs.check_frequency_unit, (self.hz_ppm_valid,)),
            ("sort_by", sort_by, sfuncs.check_sort_by, (self.dim,)),
        )

        return self._get_arrays("params", indices, funit, sort_by, merge)

    def get_errors(
        self,
        indices: Optional[Iterable[int]] = None,
        merge: bool = True,
        funit: str = "hz",
        sort_by: str = "f-1",
    ) -> Optional[Union[Iterable[np.ndarray], np.ndarray]]:
        """Return estimation result errors.

        Parameters
        ----------
        indices
            The indices of results to extract errors from. Index ``0`` corresponds to
            the first result obtained using the estimator, ``1`` corresponds to
            the next, etc.  If ``None``, all results will be used.

        merge
            If ``True``, a single array of all parameters from each specified
            estiamtion result specified will be returned. If ``False``, an iterable
            of each individual estimation result's parameters will be returned.

        funit
            The unit to express frequencies in. Must be one of ``"hz"`` and ``"ppm"``.

        sort_by
            Specifies the parameter by which the oscillators are ordered by.
            Should be one of ``"a"`` for amplitudes ``"p"`` for phase, ``"f<n>"``
            for frequency in the ``<n>``-th dimension, ``"d<n>"`` for the damping
            factor in the ``<n>``-th dimension. By setting ``<n>`` to ``-1``, the
            final (direct) dimension will be used. For 1D data, ``"f"`` and ``"d"``
            can be used to specify the frequency or damping factor.
        """
        self._check_results_exist()
        sanity_check(
            self._indices_check(indices),
            ("merge", merge, sfuncs.check_bool),
            ("funit", funit, sfuncs.check_frequency_unit, (self.hz_ppm_valid,)),
            ("sort_by", sort_by, sfuncs.check_sort_by, (self.dim,)),
        )

        return self._get_arrays("errors", indices, funit, sort_by, merge)

    def find_osc(self, params: np.ndarray) -> Tuple[int, int]:
        for i, result in enumerate(self._results):
            result_params = result.get_params()
            try:
                j = int(np.where((result_params == params).all(axis=-1))[0][0])
                return (i, j)
            except IndexError:
                pass
        return None

    def _get_arrays(
        self,
        name: str,
        indices: Optional[Iterable[int]],
        funit: str,
        sort_by: str,
        merge: bool,
    ) -> Optional[np.ndarray]:
        results = self.get_results(indices)
        arrays = [result._get_array(name, funit, sort_by) for result in results]

        if merge:
            array = np.vstack(arrays)
            sort_idx = results[0]._process_sort_by(sort_by, self.dim)

            param_array = np.vstack(
                [
                    result._get_array("params", funit, sort_by)
                    for result in results
                ]
            )

            array = array[np.argsort(param_array[:, sort_idx])]
            return array

        else:
            return arrays

    @logger
    def edit_result(
        self,
        index: int = -1,
        add_oscs: Optional[np.ndarray] = None,
        rm_oscs: Optional[Iterable[int]] = None,
        merge_oscs: Optional[Iterable[int]] = None,
        split_oscs: Optional[Dict[int, Optional[Dict]]] = None,
        **estimate_kwargs,
    ) -> None:
        self._check_results_exist()
        sanity_check(
            ("index", index, sfuncs.check_index, (len(self._results),)),
        )
        result = self.get_results(indices=[index])[0]
        params = result.get_params()
        max_osc_idx = len(params) - 1
        sanity_check(
            (
                "add_oscs", add_oscs, sfuncs.check_parameter_array, (self.dim,), {},
                True,
            ),
            (
                "rm_oscs", rm_oscs, sfuncs.check_int_list, (),
                {"min_value": 0, "max_value": max_osc_idx}, True,
            ),
            (
                "merge_oscs", merge_oscs, sfuncs.check_int_list_list,
                (), {"min_value": 0, "max_value": max_osc_idx}, True,
            ),
            (
                "split_oscs", split_oscs, sfuncs.check_split_oscs,
                (self.dim, max_osc_idx), {}, True,
            ),
        )

        idx_to_remove = []
        oscs_to_add = add_oscs

        if rm_oscs is not None:
            idx_to_remove.extend(rm_oscs)

        if merge_oscs is not None:
            for oscs in merge_oscs:
                new_osc = np.sum(params[oscs], axis=0, keepdims=True)
                new_osc[:, 1:] = new_osc[:, 1:] / float(len(oscs))
                new_osc[:, 1] = (new_osc[:, 1] + np.pi) % (2 * np.pi) - np.pi
                if oscs_to_add is None:
                    oscs_to_add = new_osc
                else:
                    oscs_to_add = np.vstack(oscs_to_add, new_osc)

                idx_to_remove.extend(oscs)

        if split_oscs is not None:
            def_sep = lambda x: self.sw()[x] / self.default_pts[x]
            def_n = 2
            def_amp_ratio = np.array([1, 1])
            def_split_dim = self.dim - 1
            for osc, split_info in split_oscs.items():
                to_split = params[osc]
                if split_info is None:
                    n, amp_ratio, split_dim = \
                        def_n, def_amp_ratio, def_split_dim
                    sep = def_sep(split_dim)
                else:
                    if "dim" in split_info:
                        split_dim = split_info["dim"]
                    else:
                        split_dim = def_split_dim

                    if "separation" in split_info:
                        sep = split_info["separation"]
                    else:
                        sep = def_sep(split_dim)

                    if ("number" not in split_info and "amp_ratio" not in split_info):
                        n = def_n
                        amp_ratio = def_n
                    elif ("number" in split_info and "amp_ratio" not in split_info):
                        n = split_info["number"]
                        amp_ratio = np.ones((n,))
                    elif ("number" not in split_info and "amp_ratio" in split_info):
                        amp_ratio = np.array(split_info["amp_ratio"])
                        n = amp_ratio.size
                    else:
                        n = split_info["number"]
                        amp_ratio = np.array(split_info["amp_ratio"])

                amps = to_split[0] * amp_ratio / amp_ratio.sum()
                # Highest frequency of all the new oscillators
                max_freq = to_split[split_dim + 2] + 0.5 * (n - 1) * sep
                # Array of all frequencies (lowest to highest)
                freqs = np.array(
                    [max_freq - i * sep for i in range(n)],
                    dtype="float64",
                )
                new_oscs = np.zeros((n, 2 * (1 + self.dim)), dtype="float64")
                new_oscs[:, 0] = amps
                new_oscs[:, 1] = to_split[1]
                for i in range(self.dim):
                    if i == split_dim:
                        new_oscs[:, 2 + i] = freqs
                    else:
                        new_oscs[:, 2 + i] = to_split[2 + i]

                new_oscs[:, 2 + self.dim :] = to_split[2 + self.dim :]

                if oscs_to_add is None:
                    oscs_to_add = new_oscs
                else:
                    oscs_to_add = np.vstack(oscs_to_add, new_oscs)

                idx_to_remove.append(osc)

        if idx_to_remove:
            params = np.delete(params, idx_to_remove, axis=0)
        if oscs_to_add is not None:
            params = np.vstack((params, oscs_to_add))

        self._optimise_after_edit(params, result, index, **estimate_kwargs)

    @logger
    def merge_oscillators(
        self,
        oscillators: Iterable[int],
        index: int = -1,
        **estimate_kwargs,
    ) -> None:
        """Merge oscillators in an estimation result.

        Removes the osccilators specified, and constructs a single new
        oscillator with a cumulative amplitude, and averaged phase,
        frequency and damping. Then runs optimisation on the updated set of
        oscillators.

        Parameters
        ----------
        oscillators
            A list of indices corresponding to the oscillators to be merged.

        index
            The index of the result to edit. Index ``0`` corresponds to the
            first result obtained using the estimator, ``1`` corresponds to the
            next, etc. By default, the most recently obtained result will be
            edited.

        estimate_kwargs
            Keyword arguments to provide to the call to :py:meth:`estimate`. Note
            that ``"initial_guess"`` and ``"region_unit"`` are set internally and
            will be ignored if given.

        Notes
        -----
        Assuming that an estimation result contains a subset of oscillators
        denoted by indices :math:`\\{m_1, m_2, \\cdots, m_J\\}`, where :math:`J
        \\leq M`, the new oscillator formed by the merging of the oscillator
        subset will possess the following parameters prior to re-running estimation:

            * :math:`a_{\\mathrm{new}} = \\sum_{i=1}^J a_{m_i}`
            * :math:`\\phi_{\\mathrm{new}} = \\frac{1}{J} \\sum_{i=1}^J
              \\phi_{m_i}`
            * :math:`f_{\\mathrm{new}} = \\frac{1}{J} \\sum_{i=1}^J f_{m_i}`
            * :math:`\\eta_{\\mathrm{new}} = \\frac{1}{J} \\sum_{i=1}^J
              \\eta_{m_i}`
        """
        self._check_results_exist()
        sanity_check(
            ("index", index, sfuncs.check_index, (len(self._results),)),
        )
        index = self._positive_index(index)
        result = self._results[index]
        x0 = result.get_params()
        sanity_check(
            (
                "oscillators", oscillators, sfuncs.check_int_list,
                (), {"min_value": 0, "max_value": x0.shape[0] - 1},
            )
        )

        to_merge = x0[oscillators]
        # Sum amps, phases, freqs and damping over the oscillators
        # to be merged.
        # keepdims ensures that the final array is [[a, φ, f, η]]
        # rather than [a, φ, f, η]
        new_osc = np.sum(to_merge, axis=0, keepdims=True)

        # Get mean for phase, frequency and damping
        new_osc[:, 1:] = new_osc[:, 1:] / float(len(oscillators))
        # wrap phase
        new_osc[:, 1] = (new_osc[:, 1] + np.pi) % (2 * np.pi) - np.pi

        x0 = np.delete(x0, oscillators, axis=0)
        x0 = np.vstack((x0, new_osc))

        self._optimise_after_edit(x0, result, index, **estimate_kwargs)

    @logger
    def split_oscillator(
        self,
        oscillator: int,
        index: int = -1,
        separation_frequency: Optional[Iterable[float]] = None,
        unit: str = "hz",
        split_number: int = 2,
        amp_ratio: Optional[Iterable[float]] = None,
        **estimate_kwargs,
    ) -> None:
        """Splits an oscillator in an estimation result into multiple oscillators.

        Removes an oscillator, and incorporates two or more oscillators whose
        cumulative amplitudes match that of the removed oscillator. Then runs
        optimisation on the updated set of oscillators.

        Parameters
        ----------
        oscillator
            The index of the oscillator to be split.

        index
            The index of the result to edit. Index ``0`` corresponds to the
            first result obtained using the estimator, ``1`` corresponds to the
            next, etc. By default, the most recently obtained result will be
            edited.

        separation_frequency
            The frequency separation given to adjacent oscillators formed
            from the splitting. If ``None``, the splitting will be set to
            ``sw / n`` in each dimension where ``sw`` is the sweep width and
            ``n`` is the number of points in the data.

        unit
            The unit that ``separation_frequency`` is expressed in.

        split_number
            The number of peaks to split the oscillator into.

        amp_ratio
            The ratio of amplitudes to be fulfilled by the newly formed
            peaks. If a list, ``len(amp_ratio) == split_number`` must be
            satisfied. The first element will relate to the highest
            frequency oscillator constructed, and the last element will
            relate to the lowest frequency oscillator constructed. If `None`,
            all oscillators will be given equal amplitudes.

        estimate_kwargs
            Keyword arguments to provide to the call to :py:meth:`estimate`. Note
            that ``"initial_guess"`` and ``"region_unit"`` are set internally and
            will be ignored if given.
        """
        self._check_results_exist()
        sanity_check(
            ("index", index, sfuncs.check_index, (len(self._results),)),
            (
                "separation_frequency", separation_frequency, sfuncs.check_float_list,
                (), {"length": self.dim, "len_one_can_be_listless": True}, True,
            ),
            ("unit", unit, sfuncs.check_frequency_unit, (self.hz_ppm_valid,)),
            ("split_number", split_number, sfuncs.check_int, (), {"min_value": 2}),
        )
        index = self._positive_index(index)
        result = self._results[index]
        x0 = result.get_params()
        sanity_check(
            (
                "amp_ratio", amp_ratio, sfuncs.check_float_list, (),
                {
                    "length": split_number,
                    "must_be_positive": True,
                },
                True,
            ),
            (
                "oscillator", oscillator, sfuncs.check_int, (),
                {"min_value": 0, "max_value": x0.shape[0] - 1},
            ),
        )

        if separation_frequency is None:
            separation_frequency = [
                sw / pts for sw, pts in zip(self.sw(unit), self.default_pts)
            ]
        else:
            if isinstance(separation_frequency, float):
                separation_frequency = [separation_frequency]
            separation_frequency = (
                self.convert(separation_frequency, f"{unit}->hz")
            )

        if amp_ratio is None:
            amp_ratio = np.ones((split_number,))
        else:
            amp_ratio = np.array(amp_ratio)

        osc = x0[oscillator]
        amps = osc[0] * amp_ratio / amp_ratio.sum()
        # Highest frequency of all the new oscillators
        max_freqs = [
            osc[i] + ((split_number - 1) * separation_frequency[i - 2] / 2)
            for i in range(2, 2 + self.dim)
        ]
        # Array of all frequencies (lowest to highest)
        freqs = np.array(
            [
                [max_freq - i * sep_freq for i in range(split_number)]
                for max_freq, sep_freq in zip(max_freqs, separation_frequency)
            ],
            dtype="float64",
        ).T

        new_oscs = np.zeros((split_number, 2 * (1 + self.dim)), dtype="float64")
        new_oscs[:, 0] = amps
        new_oscs[:, 1] = osc[1]
        new_oscs[:, 2 : 2 + self.dim] = freqs
        new_oscs[:, 2 + self.dim :] = osc[2 + self.dim :]

        x0 = np.delete(x0, oscillator, axis=0)
        x0 = np.vstack((x0, new_oscs))

        self._optimise_after_edit(x0, result, index, **estimate_kwargs)

    @logger
    def add_oscillators(
        self,
        params: np.ndarray,
        index: int = -1,
        **estimate_kwargs,
    ) -> None:
        """Add oscillators to an estimation result.

        Optimisation is carried out afterwards, on the updated set of oscillators.

        Parameters
        ----------
        params
            The parameters of new oscillators to be added. Should be of shape
            ``(n, 2 * (1 + self.dim))``, where ``n`` is the number of new
            oscillators to add. Even when one oscillator is being added this
            should be a 2D array, i.e.:

            .. code:: python3

                params = oscillators = np.array([[a, φ, f, η]])

        index
            The index of the result to edit. Index ``0`` corresponds to the
            first result obtained using the estimator, ``1`` corresponds to the
            next, etc. By default, the most recently obtained result will be
            edited.

        estimate_kwargs
            Keyword arguments to provide to the call to :py:meth:`estimate`. Note
            that ``"region"``, ``noise_region"``, ``"initial_guess"`` and
            ``"region_unit"`` are set internally and will be ignored if given.
        """
        self._check_results_exist()
        sanity_check(
            (
                "params", params, sfuncs.check_ndarray, (),
                {"dim": 2, "shape": ((1, 2 * (self.dim + 1)),)},
            ),
            ("index", index, sfuncs.check_index, (len(self._results),)),
        )
        index = self._positive_index(index)
        result = self._results[index]
        x0 = np.vstack((result.get_params(), params))
        self._optimise_after_edit(x0, result, index, **estimate_kwargs)

    @logger
    def remove_oscillators(
        self,
        oscillators: Iterable[int],
        index: int = -1,
        **estimate_kwargs,
    ) -> None:
        """Remove oscillators from an estimation result.

        Optimisation is carried out afterwards, on the updated set of oscillators.

        Parameters
        ----------
        oscillators
            A list of indices corresponding to the oscillators to be removed.

        index
            The index of the result to edit. Index ``0`` corresponds to the
            first result obtained using the estimator, ``1`` corresponds to the
            next, etc. By default, the most recently obtained result will be
            edited.

        estimate_kwargs
            Keyword arguments to provide to the call to :py:meth:`estimate`. Note
            that ``"initial_guess"`` and ``"region_unit"`` are set internally and
            will be ignored if given.
        """
        self._check_results_exist()
        sanity_check(("index", index, sfuncs.check_index, (len(self._results),)))
        index = self._positive_index(index)
        result = self._results[index]
        x0 = result.get_params()
        sanity_check(
            (
                "oscillators", oscillators, sfuncs.check_int_list, (),
                {"min_value": 0, "max_value": x0.shape[0] - 1},
            ),
        )
        x0 = np.delete(x0, oscillators, axis=0)
        self._optimise_after_edit(x0, result, index, **estimate_kwargs)

    def _optimise_after_edit(
        self,
        x0: np.ndarray,
        result: Result,
        index: int,
        **estimate_kwargs,
    ) -> None:
        for key in estimate_kwargs.keys():
            if key in ("region", "noise_region", "region_unit", "initial_guess"):
                del estimate_kwargs[key]

        self.estimate(
            result.get_region()[-1],
            result.get_noise_region()[-1],
            region_unit="hz",
            initial_guess=x0,
            fprint=False,
            _log=False,
            **estimate_kwargs,
        )

        del self._results[index]
        self._results.insert(index, self._results.pop(-1))

    def _process_indices(self, indices: Optional[Iterable[int]]) -> Iterable[int]:
        nres = len(self._results)
        if indices is None:
            return list(range(nres))
        return [idx % nres for idx in indices]

    # Commonly used sanity checks
    def _indices_check(self, x: Any):
        return (
            "indices", x, sfuncs.check_int_list, (),
            {"min_value": -len(self._results), "max_value": len(self._results) - 1},
            True,
        )


class _Estimator1DProc(Estimator):
    """Parent class for estimators which require processing/filtering in a single
    dimension. i.e. 1D, 2DJ."""

    def phase_data(self, p0: float = 0., p1: float = 0., pivot: int = 0) -> None:
        """Apply a first-order phase correction in the direct dimension.

        Parameters
        ----------
        p0
            Zero-order phase correction, in radians.

        p1
            First-order phase correction, in radians.

        pivot
            Index of the pivot. ``0`` corresponds to the leftmost point in the
            spectrum.
        """
        sanity_check(
            ("p0", p0, sfuncs.check_float),
            ("p1", p1, sfuncs.check_float),
            (
                "pivot", pivot, sfuncs.check_int, (),
                {"min_value": 0, "max_value": self.data.shape[-1] - 1},
            ),
        )
        p0 = [0. if i != self.dim - 1 else p0 for i in range(self.dim)]
        p1 = [0. if i != self.dim - 1 else p1 for i in range(self.dim)]
        pivot = [0 if i != self.dim - 1 else pivot for i in range(self.dim)]

        self._data = sig.ift(
            sig.phase(
                sig.ft(
                    self._data,
                    axes=[-1],
                ),
                p0=p0,
                p1=p1,
                pivot=pivot,
            ),
            axes=[-1],
        )

    def exp_apodisation(self, k: float):
        """Apply an exponential window function to the direct dimnsion of the data.

        The window function is computed as ``np.exp(-k * np.linspace(0, 1, n))``,
        where ``n`` is the number of points in the direct dimension.
        """
        sanity_check(("k", k, sfuncs.check_float, (), {"greater_than_zero": True}))
        self._data = sig.exp_apodisation(self._data, k, axes=[-1])

    def baseline_correction(self, min_length: int = 50) -> None:
        """TODO"""
        shape = self.data.shape
        direct_size = shape[-1]
        sanity_check(
            (
                "min_length", min_length, sfuncs.check_int, (),
                {"min_value": 1, "max_value": direct_size},
            ),
        )
        new_size = (2 * direct_size - 1) // 2
        new_shape = (*shape[:-1], new_size)
        new_data = np.zeros(new_shape, dtype="complex128")

        if self.dim == 1:
            data = np.expand_dims(self.data, axis=0)
            new_data = np.expand_dims(new_data, axis=0)
        else:
            data = self.data

        for i, fid in enumerate(data):
            spectrum = sig.ft(sig.make_virtual_echo(fid)).real
            spectrum, _ = sig.baseline_correction(spectrum, min_length=min_length)
            new_data[i] = sig.ift(spectrum)[:new_size]

        self._data = new_data[0] if self.dim == 1 else new_data
        self.default_pts = self._data.shape

    @logger
    def estimate(
        self,
        region: Optional[Tuple[float, float]] = None,
        noise_region: Optional[Tuple[float, float]] = None,
        region_unit: str = "hz",
        initial_guess: Optional[Union[np.ndarray, int]] = None,
        method: str = "gauss-newton",
        mode: str = "apfd",
        phase_variance: bool = True,
        max_iterations: Optional[int] = None,
        cut_ratio: Optional[float] = 1.1,
        mpm_trim: Optional[int] = None,
        nlp_trim: Optional[int] = None,
        fprint: bool = True,
        _log: bool = True,
    ):
        r"""Estimate a specified region of the signal.

        The basic steps that this method carries out are:

        * (Optional, but highly advised) Generate a frequency-filtered signal
          corresponding to the specified region.
        * (Optional) Generate an inital guess using the Matrix Pencil Method (MPM).
        * Apply numerical optimisation to determine a final estimate of the signal
          parameters

        Parameters
        ----------
        region
            The frequency range of interest. Should be of the form ``[left, right]``
            where ``left`` and ``right`` are the left and right bounds of the region
            of interest. If ``None``, the full signal will be considered, though
            for sufficently large and complex signals it is probable that poor and
            slow performance will be achieved.

        noise_region
            If ``region`` is not ``None``, this must be of the form ``[left, right]``
            too. This should specify a frequency range where no noticeable signals
            reside, i.e. only noise exists.

        region_unit
            One of ``"hz"`` or ``"ppm"`` Specifies the units that ``region``
            and ``noise_region`` have been given as.

        initial_guess
            If ``None``, an initial guess will be generated using the MPM,
            with the Minimum Descritpion Length being used to estimate the
            number of oscilltors present. If and int, the MPM will be used to
            compute the initial guess with the value given being the number of
            oscillators. If a NumPy array, this array will be used as the initial
            guess.

        method
            Specifies the optimisation method.

            * ``"exact"`` Uses SciPy's
              `trust-constr routine <https://docs.scipy.org/doc/scipy/reference/
              optimize.minimize-trustconstr.html\#optimize-minimize-trustconstr>`_
              The Hessian will be exact.
            * ``"gauss-newton"`` Uses SciPy's
              `trust-constr routine <https://docs.scipy.org/doc/scipy/reference/
              optimize.minimize-trustconstr.html\#optimize-minimize-trustconstr>`_
              The Hessian will be approximated based on the
              `Gauss-Newton method <https://en.wikipedia.org/wiki/
              Gauss%E2%80%93Newton_algorithm>`_
            * ``"lbfgs"`` Uses SciPy's
              `L-BFGS-B routine <https://docs.scipy.org/doc/scipy/reference/
              optimize.minimize-lbfgsb.html#optimize-minimize-lbfgsb>`_.

        mode
            A string containing a subset of the characters ``"a"`` (amplitudes),
            ``"p"`` (phases), ``"f"`` (frequencies), and ``"d"`` (damping factors).
            Specifies which types of parameters should be considered for optimisation.

        phase_variance
            Whether or not to include the variance of oscillator phases in the cost
            function. This should be set to ``True`` in cases where the signal being
            considered is derived from well-phased data.

        max_iterations
            A value specifiying the number of iterations the routine may run
            through before it is terminated. If ``None``, the default number
            of maximum iterations is set (``100`` if ``method`` is
            ``"exact"`` or ``"gauss-newton"``, and ``500`` if ``"method"`` is
            ``"lbfgs"``).

        mpm_trim
            Specifies the maximal size allowed for the filtered signal when
            undergoing the Matrix Pencil. If ``None``, no trimming is applied
            to the signal. If an int, and the filtered signal has a size
            greater than ``mpm_trim``, this signal will be set as
            ``signal[:mpm_trim]``.

        nlp_trim
            Specifies the maximal size allowed for the filtered signal when undergoing
            nonlinear programming. By default (``None``), no trimming is applied to
            the signal. If an int, and the filtered signal has a size greater than
            ``nlp_trim``, this signal will be set as ``signal[:nlp_trim]``.

        fprint
            Whether of not to output information to the terminal.

        _log
            Ignore this!
        """
        sanity_check(
            (
                "region_unit", region_unit, sfuncs.check_frequency_unit,
                (self.hz_ppm_valid,),
            ),
            (
                "initial_guess", initial_guess, sfuncs.check_initial_guess,
                (self.dim,), {}, True,
            ),
            ("method", method, sfuncs.check_one_of, ("lbfgs", "gauss-newton", "exact")),
            ("phase_variance", phase_variance, sfuncs.check_bool),
            ("mode", mode, sfuncs.check_optimiser_mode),
            (
                "max_iterations", max_iterations, sfuncs.check_int, (),
                {"min_value": 1}, True,
            ),
            ("fprint", fprint, sfuncs.check_bool),
            (
                "mpm_trim", mpm_trim, sfuncs.check_int, (),
                {"min_value": 1}, True,
            ),
            (
                "nlp_trim", nlp_trim, sfuncs.check_int, (),
                {"min_value": 1}, True,
            ),
            (
                "cut_ratio", cut_ratio, sfuncs.check_float, (),
                {"min_value": 1.}, True,
            ),
        )
        sanity_check(
            self._region_check(region, region_unit, "region"),
            self._region_check(noise_region, region_unit, "noise_region"),
        )

        if region is None:
            region_unit = "hz"
            region = self._full_region
            noise_region = None
            mpm_signal = nlp_signal = self._data
            mpm_expinfo = nlp_expinfo = self.expinfo

        else:
            region = self._process_region(region)
            noise_region = self._process_region(noise_region)
            filter_ = Filter(
                self.data,
                self.expinfo,
                region,
                noise_region,
                region_unit=region_unit,
            )

            region = filter_.get_region()
            noise_region = filter_.get_noise_region()
            mpm_signal, mpm_expinfo = filter_.get_filtered_fid(cut_ratio=cut_ratio)
            nlp_signal, nlp_expinfo = filter_.get_filtered_fid(cut_ratio=None)

        def get_trim(trim, default, signal):
            if trim is None:
                if default is None:
                    trim = signal.shape[-1]
                else:
                    trim = min(default, signal.shape[-1])
            else:
                trim = min(trim, signal.shape[-1])

            return trim

        mpm_trim = get_trim(mpm_trim, self.default_mpm_trim, mpm_signal)
        nlp_trim = get_trim(nlp_trim, self.default_nlp_trim, nlp_signal)

        if isinstance(initial_guess, np.ndarray):
            x0 = initial_guess
        else:
            oscillators = initial_guess if isinstance(initial_guess, int) else 0

            x0 = MatrixPencil(
                mpm_expinfo,
                mpm_signal[..., :mpm_trim],
                oscillators=oscillators,
                fprint=fprint,
            ).get_params()

            if x0 is None:
                self._results.append(
                    Result(
                        np.array([[]]),
                        np.array([[]]),
                        region[-1],
                        noise_region[-1],
                        self.sfo,
                    )
                )
                return

        result = NonlinearProgramming(
            nlp_expinfo,
            nlp_signal[..., :nlp_trim],
            x0,
            phase_variance=phase_variance,
            method=method,
            mode=mode,
            max_iterations=max_iterations,
            fprint=fprint,
        )

        self._results.append(
            Result(
                result.get_params(),
                result.get_errors(),
                region,
                noise_region,
                self.sfo,
            )
        )

    @logger
    def subband_estimate(
        self,
        noise_region: Tuple[float, float],
        noise_region_unit: str = "hz",
        nsubbands: Optional[int] = None,
        **estimate_kwargs,
    ) -> None:
        r"""Perform estiamtion on the entire signal via estimation of frequency-filtered
        sub-bands.

        This method splits the signal up into ``nsubbands`` equally-sized region
        and extracts parameters from each region before finally concatenating all
        the results together.

        Parameters
        ----------
        noise_region
            Specifies a frequency range where no noticeable signals reside, i.e. only
            noise exists.

        noise_region_unit
            One of ``"hz"`` or ``"ppm"``. Specifies the units that ``noise_region``
            have been given in.

        nsubbands
            The number of sub-bands to break the signal into. If ``None``, the number
            will be set as the nearest integer to the data size divided by 500.

        estimate_kwargs
            Keyword arguments to give to :py:meth:`estimate`. Note that ``region``
            and ``initial_guess`` will be ignored.
        """
        sanity_check(
            self._funit_check(noise_region_unit, "noise_region_unit"),
            ("nsubbands", nsubbands, sfuncs.check_int, (), {"min_value": 1}, True),
        )
        sanity_check(
            self._region_check(noise_region, noise_region_unit, "noise_region"),
        )

        regions, mid_regions = self._get_subbands(nsubbands)
        nsubbands = len(regions)
        noise_region = self.convert(
            (self.dim - 1) * [None] + [noise_region],
            f"{noise_region_unit}->hz",
        )[-1]

        fprint = "fprint" not in estimate_kwargs or estimate_kwargs["fprint"]
        if fprint:
            print(f"Starting sub-band estimation using {nsubbands} sub-bands:")

        for string in ("region", "region_unit", "initial_guess", "_log"):
            if string in estimate_kwargs:
                del estimate_kwargs[string]

        params, errors = None, None
        for i, (region, mid_region) in enumerate(zip(regions, mid_regions), start=1):
            if fprint:
                msg = (
                    f"--> Estimating region #{i}: "
                    f"{mid_region[0]:.2f} - {mid_region[1]:.2f}Hz"
                )
                if self.hz_ppm_valid:
                    mid_region_ppm = self.convert(
                        (self.dim - 1) * [None] + [mid_region],
                        "hz->ppm"
                    )[-1]
                    msg += f" ({mid_region_ppm[0]:.3f} - {mid_region_ppm[1]:.3f}ppm)"
                print(msg)

            self.estimate(
                region, noise_region, region_unit="hz", _log=False,
                **estimate_kwargs,
            )
            p, e = self._keep_middle_freqs(self._results.pop(), mid_region)

            if p is None:
                continue
            if params is None:
                params = p
                errors = e
            else:
                params = np.vstack((params, p))
                errors = np.vstack((errors, e))

        # Sort in order of direct-dimension freqs.
        sort_idx = np.argsort(params[:, self.dim + 1])
        params = params[sort_idx]
        errors = errors[sort_idx]

        if fprint:
            print(f"{GRE}Sub-band estimation complete.{END}")

        self._results.append(
            Result(
                params,
                errors,
                region=self._full_region,
                noise_region=None,
                sfo=self.sfo,
            )
        )

    def _get_subbands(self, nsubbands: Optional[int]):
        # N.B. This is only appropriate for Estimator1D and Estimator2DJ
        if nsubbands is None:
            nsubbands = int(np.ceil(self.data.shape[-1] / 500))

        idxs, mid_idxs = self._get_subband_indices(nsubbands)
        shifts = self.get_shifts(meshgrid=False)[-1]
        regions = [(shifts[idx[0]], shifts[idx[1]]) for idx in idxs]
        mid_regions = [(shifts[mid_idx[0]], shifts[mid_idx[1]]) for mid_idx in mid_idxs]

        return regions, mid_regions

    def _get_subband_indices(
        self,
        nsubbands: int,
    ) -> Tuple[Iterable[Tuple[int, int]], Iterable[Tuple[int, int]]]:
        # (nsubbands - 2) full-size regions plus 2 half-size regions on each end.
        size = self.data.shape[-1]
        width = int(np.ceil(2 * size / (nsubbands - 1)))
        mid_width = int(np.ceil(width / 2))
        start_factor = int(np.ceil(size / (nsubbands - 1)))
        idxs = []
        mid_idxs = []
        for i in range(0, nsubbands - 2):
            start = i * start_factor
            mid_start = int(np.ceil((i + 0.5) * start_factor))
            if i == nsubbands - 3:
                idxs.append((start, size - 1))
            else:
                idxs.append((start, start + width))
            mid_idxs.append((mid_start, mid_start + mid_width))

        idxs.insert(0, (0, start_factor))
        idxs.append(((nsubbands - 2) * start_factor, size - 1))
        mid_idxs.insert(0, (0, mid_idxs[0][0]))
        mid_idxs.append((mid_idxs[-1][-1], size - 1))

        return idxs, mid_idxs

    def _keep_middle_freqs(
        self,
        result: Result,
        mid_region: Tuple[float, float],
    ) -> Tuple[np.ndarray, np.ndarray]:
        if result.params.size == 0:
            return None, None
        to_remove = (
            list(np.nonzero(result.params[:, 1 + self.dim] >= mid_region[0])[0]) +
            list(np.nonzero(result.params[:, 1 + self.dim] < mid_region[1])[0])
        )
        return (
            np.delete(result.params, to_remove, axis=0),
            np.delete(result.errors, to_remove, axis=0),
        )

    @logger
    def write_result(
        self,
        indices: Optional[Iterable[int]] = None,
        path: Union[Path, str] = "./nmrespy_result",
        fmt: str = "txt",
        description: Optional[str] = None,
        sig_figs: Optional[int] = 5,
        sci_lims: Optional[Tuple[int, int]] = (-2, 3),
        integral_mode: str = "relative",
        force_overwrite: bool = False,
        fprint: bool = True,
        pdflatex_exe: Optional[Union[str, Path]] = None,
    ) -> None:
        """Write estimation results to text and PDF files.

        Parameters
        ----------
        indices
            The indices of results to include. Index ``0`` corresponds to the first
            result obtained using the estimator, ``1`` corresponds to the next, etc.
            If ``None``, all results will be included.

        path
            Path to save the result file to.

        fmt
            Must be one of ``"txt"`` or ``"pdf"``.

        description
            A description to add to the result file.

        sig_figs
            The number of significant figures to give to parameters. If
            ``None``, the full value will be used.

        sci_lims
            Given a value ``(-x, y)``, for ints ``x`` and ``y``, any parameter ``p``
            with a value which satisfies ``p < 10 ** -x`` or ``p >= 10 ** y`` will be
            expressed in scientific notation, rather than explicit notation.
            If ``None``, all values will be expressed explicitely.

        integral_mode
            One of ``"relative"`` or ``"absolute"``. With ``"relative"``, the smallest
            integral will be set to ``1``, and all other integrals will be scaled
            accordingly. With ``"absolute"``, the absolute integral will be computed.
            This should be used if you wish to directly compare different datasets.

        force_overwrite
            If the file specified already exists, and this is set to ``False``, the
            user will be prompted to specify that they are happy overwriting the
            current file.

        fprint
            Specifies whether or not to print information to the terminal.

        pdflatex_exe
            The path to the system's ``pdflatex`` executable.

            .. note::

               You are unlikely to need to set this manually. It is primarily
               present to specify the path to ``pdflatex.exe`` on Windows when
               the NMR-EsPy GUI has been loaded from TopSpin.
        """
        self._check_results_exist()
        sanity_check(
            self._indices_check(indices),
            ("fmt", fmt, sfuncs.check_one_of, ("txt", "pdf")),
            ("description", description, sfuncs.check_str, (), {}, True),
            ("sig_figs", sig_figs, sfuncs.check_int, (), {"min_value": 1}, True),
            ("sci_lims", sci_lims, sfuncs.check_sci_lims, (), {}, True),
            (
                "integral_mode", integral_mode, sfuncs.check_one_of,
                ("relative", "absolute"),
            ),
            ("force_overwrite", force_overwrite, sfuncs.check_bool),
            ("fprint", fprint, sfuncs.check_bool),
        )
        sanity_check(("path", path, check_saveable_path, (fmt, force_overwrite)))

        indices = self._process_indices(indices)
        results = [self._results[i] for i in indices]
        writer = ResultWriter(
            self.expinfo,
            [result.get_params() for result in results],
            [result.get_errors() for result in results],
            description,
        )
        region_unit = "ppm" if self.hz_ppm_valid else "hz"

        titles = []
        for result in results:
            if result.get_region() is None:
                titles.append("Full signal")
            else:
                left, right = result.get_region(region_unit)[-1]
                titles.append(
                    f"{left:.3f} - {right:.3f} {region_unit}".replace("h", "H")
                )

        writer.write(
            path=path,
            fmt=fmt,
            titles=titles,
            parameters_sig_figs=sig_figs,
            parameters_sci_lims=sci_lims,
            integral_mode=integral_mode,
            force_overwrite=True,
            fprint=fprint,
            pdflatex_exe=pdflatex_exe,
        )

    def _plot_regions(
        self,
        indices: Iterable[int],
        region_unit: str,
    ) -> Tuple[Iterable[Iterable[int]], Iterable[Tuple[float, float]]]:
        regions = sorted(
            [
                (i, result.get_region(unit=region_unit)[-1])
                for i, result in enumerate(self.get_results())
                if i in indices
            ],
            key=lambda x: x[1][0],
            reverse=True,
        )

        # Merge overlapping/bordering regions
        merge_indices = []
        merge_regions = []
        for idx, region in regions:
            assigned = False
            for i, reg in enumerate(merge_regions):
                if max(region) >= min(reg):
                    merge_regions[i] = (max(reg), min(region))
                    assigned = True
                elif min(region) >= max(reg):
                    merge_regions[i] = (max(region), min(reg))
                    assigned = True

                if assigned:
                    merge_indices[i].append(idx)
                    break

            if not assigned:
                merge_indices.append([idx])
                merge_regions.append(region)

        return merge_indices, merge_regions

    def _configure_axes(
        self,
        axs: np.ndarray[mpl.Axes.axes],
        regions: Iterable[Tuple[float, float]],
    ) -> None:
        for ax in axs[0]:
            ax.spines["bottom"].set_visible(False)
        for ax in axs[1]:
            ax.spines["top"].set_visible(False)
        for region, ax_col in zip(regions, axs.T):
            for ax in ax_col:
                ax.set_xlim(*region)

        if len(regions) > 1:
            for axs_col in axs[:, :-1]:
                for ax in axs_col:
                    ax.spines["right"].set_visible(False)
            for axs_col in axs[:, 1:]:
                for ax in axs_col:
                    ax.spines["left"].set_visible(False)

            break_kwargs = {
                "marker": [(-1, -3), (1, 3)],
                "markersize": 10,
                "linestyle": "none",
                "color": "k",
                "mec": "k",
                "mew": 1,
                "clip_on": False,
            }
            for ax in axs[0, :-1]:
                ax.plot([1], [1], transform=ax.transAxes, **break_kwargs)
            for ax in axs[0, 1:]:
                ax.plot([0], [1], transform=ax.transAxes, **break_kwargs)
            for ax in axs[1, :-1]:
                ax.plot([1], [0], transform=ax.transAxes, **break_kwargs)
            for ax in axs[1, 1:]:
                ax.plot([0], [0], transform=ax.transAxes, **break_kwargs)
                ax.set_yticks([])


    def _region_check(self, region: Any, region_unit: str, name: str):
        return (
            name, region, sfuncs.check_region,
            (
                (self.sw(region_unit)[-1],),
                (self.offset(region_unit)[-1],)
            ),
            {}, True,
        )

    def _process_region(self, direct_region: Tuple[float, float]):
        return tuple(
            [
                tuple(direct_region) if i == self.dim - 1
                else None
                for i in range(self.dim)
            ]
        )

    @property
    def _full_region(self) -> Tuple[float, float]:
        return self.convert(
            self._process_region((0, self.data.shape[-1] - 1)),
            "idx->hz",
        )


class Result(ResultFetcher):

    def __init__(
        self,
        params: np.ndarray,
        errors: np.ndarray,
        region: Iterable[Tuple[float, float]],
        noise_region: Iterable[Tuple[float, float]],
        sfo: Iterable[float],
    ) -> None:
        self.params = params
        self.errors = errors
        self.region = region
        self.noise_region = noise_region
        super().__init__(sfo)

    def get_region(self, unit: str = "hz"):
        sanity_check(
            ("unit", unit, sfuncs.check_frequency_unit, (self.hz_ppm_valid,)),
        )
        return self.convert(self.region, f"hz->{unit}")

    def get_noise_region(self, unit: str = "hz"):
        sanity_check(
            ("unit", unit, sfuncs.check_frequency_unit, (self.hz_ppm_valid,)),
        )
        return self.convert(self.noise_region, f"hz->{unit}")
