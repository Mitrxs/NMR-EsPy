# _proc_onedim.py
# Simon Hulse
# simon.hulse@chem.ox.ac.uk
# Last Edited: Wed 29 Mar 2023 15:18:43 BST

import copy
from pathlib import Path
from typing import Any, Iterable, Optional, Tuple, Union

import matplotlib as mpl
from matplotlib import cm, pyplot as plt
import numpy as np
from pybaselines.classification import dietrich

import nmrespy as ne
from nmrespy.estimators import Estimator, logger, Result
from nmrespy.freqfilter import Filter
from nmrespy.mpm import MatrixPencil
from nmrespy.nlp import nonlinear_programming
from nmrespy.write import ResultWriter
from nmrespy._colors import GRE, END, USE_COLORAMA
from nmrespy._files import check_saveable_path
from nmrespy._sanity import sanity_check, funcs as sfuncs

if USE_COLORAMA:
    import colorama
    colorama.init()


class _Estimator1DProc(Estimator):
    """Parent class for estimators which require processing/filtering in a single
    dimension. i.e. 1D, 2DJ."""

    @property
    def spectrum_first_direct(self) -> np.ndarray:
        """Generate a 1D spectrum of the first signal in the direct dimension.

        Generated by taking the first direct-dimension slice (``self.data[0]``),
        halving the initial point, and applying FT.
        """
        data = copy.deepcopy(self.data[0])
        data[0] *= 0.5
        return ne.sig.ft(data)

    def phase_data(self, p0: float = 0., p1: float = 0., pivot: int = 0) -> None:
        """Apply a first-order phase correction in the direct dimension.

        Parameters
        ----------
        p0
            Zero-order phase correction, in radians.

        p1
            First-order phase correction, in radians.

        pivot
            Index of the pivot. ``0`` corresponds to the leftmost point in the
            spectrum.

        See also
        --------
        :py:meth:`manual_phase_data`
        """
        sanity_check(
            ("p0", p0, sfuncs.check_float),
            ("p1", p1, sfuncs.check_float),
            (
                "pivot", pivot, sfuncs.check_int, (),
                {"min_value": 0, "max_value": self.data.shape[-1] - 1},
            ),
        )

        ndim = self.data.ndim
        p0 = (ndim - 1) * [0.] + [p0]
        p1 = (ndim - 1) * [0.] + [p1]
        pivot = (ndim - 1) * [0.] + [pivot]

        spec = self.data
        spec[..., 0] *= 0.5

        self._data = ne.sig.ift(
            ne.sig.phase(
                ne.sig.ft(
                    spec,
                    axes=[-1],
                ),
                p0=p0,
                p1=p1,
                pivot=pivot,
            ),
            axes=[-1],
        )

    def manual_phase_data(
        self,
        max_p1: float = 10 * np.pi,
    ) -> Tuple[float, float]:
        """Manually phase the data using a Graphical User Interface.

        Parameters
        ----------
        max_p1
            The largest permitted first order correction (rad). Set this to a larger
            value than the default (10π) if you anticipate having to apply a
            very large first order correction.

        Returns
        -------
        p0
            Zero order phase (rad)

        p1
            First prder phase (rad)

        See also
        --------
        :py:meth:`phase_data`
        """
        sanity_check(
            ("max_p1", max_p1, sfuncs.check_float, (), {"greater_than_zero": True}),
        )
        if self.data.ndim == 1:
            spectrum = self.spectrum
        else:
            spectrum = self.spectrum_first_direct

        p0, p1 = ne.sig.manual_phase_data(spectrum, max_p1=[max_p1])
        p0, p1 = p0[0], p1[0]
        self.phase_data(p0=p0, p1=p1)
        return p0, p1

    def exp_apodisation(self, k: float):
        """Apply an exponential window function to the direct dimnsion of the data.

        The window function is computed as ``np.exp(-k * np.linspace(0, 1, n))``,
        where ``n`` is the number of points in the direct dimension.
        """
        sanity_check(("k", k, sfuncs.check_float, (), {"greater_than_zero": True}))
        self._data = ne.sig.exp_apodisation(self._data, k, axes=[-1])

    def baseline_correction(self, min_length: int = 50) -> None:
        """Apply baseline correction to the estimator's data.

        The algorithm applied is desribed in [#]_. This uses an implementation
        provided by `pybaselines
        <https://pybaselines.readthedocs.io/en/latest/api/pybaselines/api/index.html#pybaselines.api.Baseline.fabc>`_.

        Parameters
        ----------
        min_length
            *From the pybaseline docs:* Any region of consecutive baseline
            points less than ``min_length`` is considered to be a false
            positive and all points in the region are converted to peak points.
            A higher ``min_length`` ensures less points are falsely assigned as
            baseline points.

        References
        ----------
        .. [#] Cobas, J., et al. A new general-purpose fully automatic
           baseline-correction procedure for 1D and 2D NMR data. Journal of
           Magnetic Resonance, 2006, 183(1), 145-151.
        """
        shape = self.data.shape
        direct_size = shape[-1]
        sanity_check(
            (
                "min_length", min_length, sfuncs.check_int, (),
                {"min_value": 1, "max_value": direct_size},
            ),
        )
        new_size = (2 * direct_size - 1) // 2
        new_shape = (*shape[:-1], new_size)
        new_data = np.zeros(new_shape, dtype="complex128")

        if self.data.ndim == 1:
            data = np.expand_dims(self.data, axis=0)
            new_data = np.expand_dims(new_data, axis=0)
        else:
            data = self.data

        for i, fid in enumerate(data):
            spectrum = ne.sig.ft(ne.sig.make_virtual_echo(fid)).real
            spectrum, _ = ne.sig.baseline_correction(spectrum, min_length=min_length)
            new_data[i] = ne.sig.ift(spectrum)[:new_size]

        self._data = new_data[0] if self.data.ndim == 1 else new_data
        new_default_pts = list(self.default_pts)
        new_default_pts[-1] = self._data.shape[-1]
        self._default_pts = tuple(new_default_pts)

    @logger
    def estimate(
        self,
        region: Optional[Tuple[float, float]] = None,
        noise_region: Optional[Tuple[float, float]] = None,
        region_unit: str = "hz",
        initial_guess: Optional[Union[np.ndarray, int]] = None,
        mode: str = "apfd",
        amp_thold: Optional[float] = None,
        phase_variance: bool = True,
        cut_ratio: Optional[float] = 1.1,
        mpm_trim: Optional[int] = None,
        nlp_trim: Optional[int] = None,
        hessian: str = "gauss-newton",
        max_iterations: Optional[int] = None,
        negative_amps: str = "remove",
        output_mode: Optional[int] = 10,
        save_trajectory: bool = False,
        epsilon: float = 1.0e-8,
        eta: float = 0.15,
        initial_trust_radius: float = 1.0,
        max_trust_radius: float = 4.0,
        check_neg_amps_every: int = 10,
        _log: bool = True,
        **optimiser_kwargs,
    ):
        r"""Estimate a specified region of the signal.

        The basic steps that this method carries out are:

        * (Optional, but highly advised) Generate a frequency-filtered "sub-FID"
          corresponding to a specified region of interest.
        * (Optional) Generate an initial guess using the Minimum Description
          Length (MDL) [#]_ and Matrix Pencil Method (MPM) [#]_ [#]_ [#]_ [#]_
        * Apply numerical optimisation to determine a final estimate of the signal
          parameters. The optimisation routine employed is the Trust Newton Conjugate
          Gradient (NCG) algorithm ([#]_ , Algorithm 7.2).

        Parameters
        ----------
        region
            The frequency range of interest. Should be of the form ``[left, right]``
            where ``left`` and ``right`` are the left and right bounds of the region
            of interest in Hz or ppm (see ``region_unit``). If ``None``, the
            full signal will be considered, though for sufficently large and
            complex signals it is probable that poor and slow performance will
            be realised.

        noise_region
            If ``region`` is not ``None``, this must be of the form ``[left, right]``
            too. This should specify a frequency range where no noticeable signals
            reside, i.e. only noise exists.

        region_unit
            One of ``"hz"`` or ``"ppm"`` Specifies the units that ``region``
            and ``noise_region`` have been given as.

        initial_guess
            * If ``None``, an initial guess will be generated using the MPM
              with the MDL being used to estimate the number of oscillators
              present.
            * If an int, the MPM will be used to compute the initial guess with
              the value given being the number of oscillators.
            * If a NumPy array, this array will be used as the initial guess.

        hessian
            Specifies how to construct the Hessian matrix.

            * If ``"exact"``, the exact Hessian will be used.
            * If ``"gauss-newton"``, the Hessian will be approximated as is
              done with the Gauss-Newton method. See the *"Derivation from
              Newton's method"* section of `this article
              <https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm>`_.

        mode
            A string containing a subset of the characters ``"a"`` (amplitudes),
            ``"p"`` (phases), ``"f"`` (frequencies), and ``"d"`` (damping factors).
            Specifies which types of parameters should be considered for optimisation.
            In most scenarios, you are likely to want the default value, ``"apfd"``.

        amp_thold
            A value that imposes a threshold for deleting oscillators of
            negligible ampltiude.

            * If ``None``, does nothing.
            * If a float, oscillators with amplitudes satisfying :math:`a_m <
              a_{\mathrm{thold}} \lVert \boldsymbol{a} \rVert_2` will be
              removed from the parameter array, where :math:`\lVert
              \boldsymbol{a} \rVert_2` is the Euclidian norm of the vector of
              all the oscillator amplitudes. It is advised to set ``amp_thold``
              at least a couple of orders of magnitude below 1.

        phase_variance
            Whether or not to include the variance of oscillator phases in the cost
            function. This should be set to ``True`` in cases where the signal being
            considered is derived from well-phased data.

        mpm_trim
            Specifies the maximal size allowed for the filtered signal when
            undergoing the Matrix Pencil. If ``None``, no trimming is applied
            to the signal. If an int, and the filtered signal has a size
            greater than ``mpm_trim``, this signal will be set as
            ``signal[:mpm_trim]``.

        nlp_trim
            Specifies the maximal size allowed for the filtered signal when undergoing
            nonlinear programming. By default (``None``), no trimming is applied to
            the signal. If an int, and the filtered signal has a size greater than
            ``nlp_trim``, this signal will be set as ``signal[:nlp_trim]``.

        max_iterations
            A value specifiying the number of iterations the routine may run
            through before it is terminated. If ``None``, a default number
            of maximum iterations is set, based on the the data dimension and
            the value of ``hessian``.

        negative_amps
            Indicates how to treat oscillators which have gained negative
            amplitudes during the optimisation.

            * ``"remove"`` will result in such oscillators being purged from
              the parameter estimate. The optimisation routine will the be
              re-run recursively until no oscillators have a negative
              amplitude.
            * ``"flip_phase"`` will retain oscillators with negative
              amplitudes, but the the amplitudes will be multiplied by -1,
              and a π radians phase shift will be applied.
            * ``"ignore"`` will do nothing (negative amplitude oscillators will remain).

        output_mode
            Dictates what information is sent to stdout.

            * If ``None``, nothing will be sent.
            * If ``0``, only a message on the outcome of the optimisation will
              be sent.
            * If a positive int ``k``, information on the cost function,
              gradient norm, and trust region radius is sent every kth
              iteration.

        save_trajectory
            If ``True``, a list of parameters at each iteration will be saved, and
            accessible via the ``trajectory`` attribute.

            .. warning:: Not implemented yet!

        epsilon
            Sets the convergence criterion. Convergence will occur when
            :math:`\lVert \boldsymbol{g}_k \rVert_2 < \epsilon`.

        eta
            Criterion for accepting an update. An update will be accepted if
            the ratio of the actual reduction and the predicted reduction is
            greater than ``eta``:

            .. math ::

                \rho_k = \frac{f(x_k) - f(x_k - p_k)}{m_k(0) - m_k(p_k)} > \eta

        initial_trust_radius
            The initial value of the radius of the trust region.

        max_trust_radius
            The largest permitted radius for the trust region.

        check_neg_amps_every
            For every iteration that is a multiple of this, negative amplitudes
            will be checked for and dealt with if found.

        _log
            Ignore this!

        References
        ----------
        .. [#] Yingbo Hua and Tapan K Sarkar. “Matrix pencil method for estimating
           parameters of exponentially damped/undamped sinusoids in noise”. In:
           IEEE Trans. Acoust., Speech, Signal Process. 38.5 (1990), pp. 814–824.

        .. [#] Yung-Ya Lin et al. “A novel detection–estimation scheme for noisy
           NMR signals: applications to delayed acquisition data”. In: J. Magn.
           Reson. 128.1 (1997), pp. 30–41.

        .. [#] Yingbo Hua. “Estimating two-dimensional frequencies by matrix
           enhancement and matrix pencil”. In: [Proceedings] ICASSP 91: 1991
           International Conference on Acoustics, Speech, and Signal Processing.
           IEEE. 1991, pp. 3073–3076.

        .. [#] Fang-Jiong Chen et al. “Estimation of two-dimensional frequencies
           using modified matrix pencil method”. In: IEEE Trans. Signal Process.
           55.2 (2007), pp. 718–724.

        .. [#] M. Wax, T. Kailath, Detection of signals by information theoretic
           criteria, IEEE Transactions on Acoustics, Speech, and Signal Processing
           33 (2) (1985) 387–392.

        .. [#] Jorge Nocedal and Stephen J. Wright. Numerical optimization. 2nd
               ed. Springer series in operations research. New York: Springer,
               2006.
        """
        sanity_check(
            (
                "region_unit", region_unit, sfuncs.check_frequency_unit,
                (self.hz_ppm_valid,),
            ),
            (
                "initial_guess", initial_guess, sfuncs.check_initial_guess,
                (self.dim,), {}, True,
            ),
            ("hessian", hessian, sfuncs.check_one_of, ("gauss-newton", "exact")),
            ("phase_variance", phase_variance, sfuncs.check_bool),
            ("mode", mode, sfuncs.check_optimiser_mode),
            (
                "amp_thold", amp_thold, sfuncs.check_float, (),
                {"greater_than_zero": True}, True,
            ),
            (
                "mpm_trim", mpm_trim, sfuncs.check_int, (),
                {"min_value": 1}, True,
            ),
            (
                "nlp_trim", nlp_trim, sfuncs.check_int, (),
                {"min_value": 1}, True,
            ),
            (
                "cut_ratio", cut_ratio, sfuncs.check_float, (),
                {"min_value": 1.}, True,
            ),
            (
                "max_iterations", max_iterations, sfuncs.check_int, (),
                {"min_value": 1}, True,
            ),
            (
                "negative_amps", negative_amps, sfuncs.check_one_of,
                ("remove", "flip_phase", "ignore"),
            ),
            ("output_mode", output_mode, sfuncs.check_int, (), {"min_value": 0}, True),
            ("save_trajectory", save_trajectory, sfuncs.check_bool),
            (
                "epsilon", epsilon, sfuncs.check_float, (),
                {"min_value": np.finfo(float).eps},
            ),
            ("eta", eta, sfuncs.check_float, (), {"min_value": 0.0, "max_value": 1.0}),
            (
                "initial_trust_radius", initial_trust_radius, sfuncs.check_float, (),
                {"greater_than_zero": True},
            ),
        )
        sanity_check(
            self._region_check(region, region_unit, "region"),
            self._region_check(noise_region, region_unit, "noise_region"),
            (
                "max_trust_radius", max_trust_radius, sfuncs.check_float, (),
                {"min_value": initial_trust_radius},
            ),
            (
                "check_neg_amps_every", check_neg_amps_every, sfuncs.check_int, (),
                {"min_value": 1, "max_value": max_iterations},
            ),
        )

        (
            region,
            noise_region,
            mpm_expinfo,
            nlp_expinfo,
            mpm_signal,
            nlp_signal,
        ) = self._filter_signal(
            region, noise_region, region_unit, mpm_trim, nlp_trim, cut_ratio,
        )

        # Unless the estimator is `EstimatorInvRec`, these do nothing.
        # Otherwise, it makes the data peaks positive for both the MPM signal and
        # the first increment of the NLP data.
        mpm_signal = self._proc_mpm_signal(mpm_signal)
        nlp_signal = self._proc_nlp_signal(nlp_signal)

        if isinstance(initial_guess, np.ndarray):
            x0 = initial_guess
        else:
            oscillators = initial_guess if isinstance(initial_guess, int) else 0

            x0 = MatrixPencil(
                mpm_expinfo,
                mpm_signal,
                oscillators=oscillators,
                fprint=isinstance(output_mode, int),
            ).get_params()

            if x0 is None:
                self._results.append(
                    Result(
                        np.array([[]]),
                        np.array([[]]),
                        region[-1],
                        noise_region[-1],
                        self.sfo,
                    )
                )
                return

        if max_iterations is None:
            if hessian == "exact":
                max_iterations = self.default_max_iterations_exact_hessian
            elif hessian == "gauss-newton":
                max_iterations = self.default_max_iterations_gn_hessian

        optimiser_kwargs = {
            "phase_variance": phase_variance,
            "hessian": hessian,
            "mode": mode,
            "amp_thold": amp_thold,
            "max_iterations": max_iterations,
            "negative_amps": negative_amps,
            "output_mode": output_mode,
            "save_trajectory": save_trajectory,
            "epsilon": epsilon,
            "eta": eta,
            "initial_trust_radius": initial_trust_radius,
            "max_trust_radius": max_trust_radius,
            "check_neg_amps_every": check_neg_amps_every,
        }

        self._run_optimisation(
            nlp_expinfo,
            nlp_signal,
            x0,
            region,
            noise_region,
            **optimiser_kwargs,
        )

    def _filter_signal(
        self,
        region: Optional[Tuple[float, float]],
        noise_region: Optional[Tuple[float, float]],
        region_unit: str,
        mpm_trim: Optional[int],
        nlp_trim: Optional[int],
        cut_ratio: Optional[float],
    ) -> None:
        # This method is uused by `Estimator1D` and `Estimator2DJ`.
        # It is overwritten by `EstimatorSeq1D`.
        if region is None:
            region_unit = "hz"
            region = self._full_region
            noise_region = None
            mpm_signal = nlp_signal = self.data
            mpm_expinfo = nlp_expinfo = self.expinfo

        else:
            region = self._process_region(region)
            noise_region = self._process_region(noise_region)
            filter_ = Filter(
                self.data,
                self.expinfo,
                region,
                noise_region,
                region_unit=region_unit,
                twodim_dtype=None if self.dim == 1 else "hyper",
            )

            region = filter_.get_region()
            noise_region = filter_.get_noise_region()
            mpm_signal, mpm_expinfo = filter_.get_filtered_fid(cut_ratio=cut_ratio)
            nlp_signal, nlp_expinfo = filter_.get_filtered_fid(cut_ratio=None)

        mpm_trim = self._get_trim("mpm", mpm_trim, mpm_signal.shape[-1])
        nlp_trim = self._get_trim("nlp", nlp_trim, nlp_signal.shape[-1])

        return (
            region,
            noise_region,
            mpm_expinfo,
            nlp_expinfo,
            mpm_signal[..., :mpm_trim],
            nlp_signal[..., :nlp_trim],
        )

    def _get_trim(self, type_: str, trim: Optional[float], size: float):
        default = (
            self.default_mpm_trim if type_ == "mpm" else
            self.default_nlp_trim
        )

        if trim is None:
            if default is None:
                trim = size
            else:
                trim = min(default, size)
        else:
            trim = min(trim, size)

        return trim

    @staticmethod
    def _proc_mpm_signal(mpm_signal: np.ndarray) -> np.ndarray:
        """Used for tweaking MPM signal before estimation if required.

        For EstimatorInvRec, the spectrum is multiplied by -1 to make the signal
        positive.
        """
        return mpm_signal

    @staticmethod
    def _proc_nlp_signal(nlp_signal: np.ndarray) -> np.ndarray:
        """Used for tweaking NLP signal before estimation if required.

        For EstimatorInvRec, the first increment of the spectrum is multiplied by
        -1 to make the signal positive.
        """
        return nlp_signal

    def _run_optimisation(
        self,
        nlp_expinfo,
        nlp_signal,
        x0,
        region,
        noise_region,
        **optimiser_kwargs,
    ) -> None:
        # This is called by `Estimator1D` and `Estimator2DJ`.
        # It is overwritten by `EstimatorSeq1D`.
        result = nonlinear_programming(
            nlp_expinfo,
            nlp_signal,
            x0,
            **optimiser_kwargs,
        )

        self._results.append(
            Result(
                result.x,
                result.errors,
                region,
                noise_region,
                self.sfo,
            )
        )

    def predict_regions(
        self,
        unit: str = "hz",
        min_baseline_length: int = 15,
        true_region_filter: int = 200,
    ) -> Iterable[Tuple[float, float]]:
        # TODO: docstring
        # TODO: sanity checking
        if self.data.ndim == 1:
            data = copy.deepcopy(self.data)
        else:
            data = self.data[0]
        data[0] *= 0.5
        spectrum = ne.sig.ft(data).real
        shifts = self.get_shifts(unit=unit)[-1]
        mask = dietrich(
            spectrum,
            x_data=shifts,
            min_length=min_baseline_length,
        )[1]["mask"].astype(int)
        mask_diff = np.abs(np.diff(mask))
        flip_idxs, = np.nonzero(mask_diff == 1)
        flip_iter = iter(flip_idxs)

        region_idxs = []
        if mask[0] == 0:
            region_idxs.append(0)
        else:
            region_idxs.append(int(next(flip_iter)))
        region_idxs.extend([int(idx) for idx in flip_iter])
        if mask[-1] == 0:
            region_idxs.append(mask.size - 1)

        region_freqs = iter(self.convert([region_idxs], f"idx->{unit}")[0])
        regions = [(l, r) for l, r in zip(region_freqs, region_freqs)]  # noqa: E741

        # Filter away sufficiently small regions
        width_threshold = (
            self.convert([0], f"idx->{unit}")[0] -
            self.convert([true_region_filter], f"idx->{unit}")[0]
        )
        regions = list(filter(lambda r: r[0] - r[1] >= width_threshold, regions))

        return regions

    def view_proposed_regions(
        self,
        regions: Iterable[Tuple[float, float]],
        unit: str = "hz",
    ) -> None:
        # TODO docstring
        # TODO sanity checking
        if self.data.ndim == 1:
            data = copy.deepcopy(self.data)
        else:
            data = self.data[0]
        data[0] *= 0.5
        spectrum = ne.sig.ft(data).real
        shifts = self.get_shifts(unit=unit)[-1]

        fig, ax = plt.subplots()
        ax.set_xlim(shifts[0], shifts[-1])
        ax.plot(shifts, spectrum, color="k")
        colors = cm.viridis(np.linspace(0, 1, len(regions)))
        for region, color in zip(regions, colors):
            ax.axvspan(
                region[0],
                region[1],
                facecolor=color,
                alpha=0.6,
                edgecolor=None,
            )

        ax.set_yticks([])
        ax.set_xlabel(self._axis_freq_labels(unit)[-1])

        plt.show()

    @logger
    def subband_estimate(
        self,
        noise_region: Tuple[float, float],
        noise_region_unit: str = "hz",
        nsubbands: Optional[int] = None,
        **estimate_kwargs,
    ) -> None:
        r"""Perform estiamtion on the entire signal via estimation of
        frequency-filtered sub-bands.

        This method splits the signal up into ``nsubbands`` equally-sized region
        and extracts parameters from each region before finally concatenating all
        the results together.

        .. warning::

            This method is a work-in-progress. It is unlikely to produce decent
            results at the moment! I aim to improve the way that regions are
            created in the future.

        Parameters
        ----------
        noise_region
            Specifies a frequency range where no noticeable signals reside, i.e. only
            noise exists.

        noise_region_unit
            One of ``"hz"`` or ``"ppm"``. Specifies the units that ``noise_region``
            have been given in.

        nsubbands
            The number of sub-bands to break the signal into. If ``None``, the number
            will be set as the nearest integer to the data size divided by 500.

        estimate_kwargs
            Keyword arguments to give to :py:meth:`estimate`. Note that ``region``
            and ``initial_guess`` will be ignored.
        """
        sanity_check(
            self._funit_check(noise_region_unit, "noise_region_unit"),
            ("nsubbands", nsubbands, sfuncs.check_int, (), {"min_value": 1}, True),
        )
        sanity_check(
            self._region_check(noise_region, noise_region_unit, "noise_region"),
        )

        regions, mid_regions = self._get_subbands(nsubbands)
        nsubbands = len(regions)
        noise_region = self.convert(
            (self.dim - 1) * [None] + [noise_region],
            f"{noise_region_unit}->hz",
        )[-1]

        fprint = "fprint" not in estimate_kwargs or estimate_kwargs["fprint"]
        if fprint:
            print(f"Starting sub-band estimation using {nsubbands} sub-bands:")

        for string in ("region", "region_unit", "initial_guess", "_log"):
            if string in estimate_kwargs:
                del estimate_kwargs[string]

        params, errors = None, None
        for i, (region, mid_region) in enumerate(zip(regions, mid_regions), start=1):
            if fprint:
                msg = (
                    f"--> Estimating region #{i}: "
                    f"{mid_region[0]:.2f} - {mid_region[1]:.2f}Hz"
                )
                if self.hz_ppm_valid:
                    mid_region_ppm = self.convert(
                        (self.dim - 1) * [None] + [mid_region],
                        "hz->ppm"
                    )[-1]
                    msg += f" ({mid_region_ppm[0]:.3f} - {mid_region_ppm[1]:.3f}ppm)"
                print(msg)

            self.estimate(
                region, noise_region, region_unit="hz", _log=False,
                **estimate_kwargs,
            )
            p, e = self._keep_middle_freqs(self._results.pop(), mid_region)

            if p is None:
                continue
            if params is None:
                params = p
                errors = e
            else:
                params = np.vstack((params, p))
                errors = np.vstack((errors, e))

        # Sort in order of direct-dimension freqs.
        sort_idx = np.argsort(params[:, self.dim + 1])
        params = params[sort_idx]
        errors = errors[sort_idx]

        if fprint:
            print(f"{GRE}Sub-band estimation complete.{END}")

        self._results.append(
            Result(
                params,
                errors,
                region=self._full_region,
                noise_region=None,
                sfo=self.sfo,
            )
        )

    def _get_subbands(self, nsubbands: Optional[int]):
        # N.B. This is only appropriate for Estimator1D and Estimator2DJ
        if nsubbands is None:
            nsubbands = int(np.ceil(self.data.shape[-1] / 500))

        idxs, mid_idxs = self._get_subband_indices(nsubbands)
        shifts = self.get_shifts(meshgrid=False)[-1]
        regions = [(shifts[idx[0]], shifts[idx[1]]) for idx in idxs]
        mid_regions = [(shifts[mid_idx[0]], shifts[mid_idx[1]]) for mid_idx in mid_idxs]

        return regions, mid_regions

    def _get_subband_indices(
        self,
        nsubbands: int,
    ) -> Tuple[Iterable[Tuple[int, int]], Iterable[Tuple[int, int]]]:
        # (nsubbands - 2) full-size regions plus 2 half-size regions on each end.
        size = self.data.shape[-1]
        width = int(np.ceil(2 * size / (nsubbands - 1)))
        mid_width = int(np.ceil(width / 2))
        start_factor = int(np.ceil(size / (nsubbands - 1)))
        idxs = []
        mid_idxs = []
        for i in range(0, nsubbands - 2):
            start = i * start_factor
            mid_start = int(np.ceil((i + 0.5) * start_factor))
            if i == nsubbands - 3:
                idxs.append((start, size - 1))
            else:
                idxs.append((start, start + width))
            mid_idxs.append((mid_start, mid_start + mid_width))

        idxs.insert(0, (0, start_factor))
        idxs.append(((nsubbands - 2) * start_factor, size - 1))
        mid_idxs.insert(0, (0, mid_idxs[0][0]))
        mid_idxs.append((mid_idxs[-1][-1], size - 1))

        return idxs, mid_idxs

    def _keep_middle_freqs(
        self,
        result: Result,
        mid_region: Tuple[float, float],
    ) -> Tuple[np.ndarray, np.ndarray]:
        if result.params.size == 0:
            return None, None
        to_remove = (
            list(np.nonzero(result.params[:, 1 + self.dim] >= mid_region[0])[0]) +
            list(np.nonzero(result.params[:, 1 + self.dim] < mid_region[1])[0])
        )
        return (
            np.delete(result.params, to_remove, axis=0),
            np.delete(result.errors, to_remove, axis=0),
        )

    @logger
    def write_result(
        self,
        path: Union[Path, str] = "./nmrespy_result",
        indices: Optional[Iterable[int]] = None,
        fmt: str = "txt",
        description: Optional[str] = None,
        sig_figs: Optional[int] = 5,
        sci_lims: Optional[Tuple[int, int]] = (-2, 3),
        integral_mode: str = "relative",
        force_overwrite: bool = False,
        fprint: bool = True,
        pdflatex_exe: Optional[Union[str, Path]] = None,
    ) -> None:
        r"""Write estimation result tables to a text/PDF file.

        Parameters
        ----------
        path
            Path to save the result file to.

        indices
            see :ref:`INDICES`

        fmt
            Must be one of ``"txt"`` or ``"pdf"``. If you wish to generate a PDF, you
            must have a LaTeX installation. See :ref:`LATEX_INSTALL`\.

        description
            Descriptive text to add to the top of the file.

        sig_figs
            The number of significant figures to give to parameters. If
            ``None``, the full value will be used. By default this is set to ``5``.

        sci_lims
            Given a value ``(-x, y)`` with ints ``x`` and ``y``, any parameter ``p``
            with a value which satisfies ``p < 10 ** -x`` or ``p >= 10 ** y`` will be
            expressed in scientific notation. If ``None``, scientific notation
            will never be used.

        integral_mode
            One of ``"relative"`` or ``"absolute"``.

            * If ``"relative"``, the smallest integral will be set to ``1``,
              and all other integrals will be scaled accordingly.
            * If ``"absolute"``, the absolute integral will be computed. This
              should be used if you wish to directly compare different datasets.

        force_overwrite
            Defines behaviour if the specified path already exists:

            * If ``False``, the user will be prompted if they are happy
              overwriting the current file.
            * If ``True``, the current file will be overwritten without prompt.

        fprint
            Specifies whether or not to print information to the terminal.

        pdflatex_exe
            The path to the system's ``pdflatex`` executable.

            .. note::

               You are unlikely to need to set this manually. It is primarily
               present to specify the path to ``pdflatex.exe`` on Windows when
               the NMR-EsPy GUI has been loaded from TopSpin.
        """
        self._check_results_exist()
        sanity_check(
            self._indices_check(indices),
            ("fmt", fmt, sfuncs.check_one_of, ("txt", "pdf")),
            ("description", description, sfuncs.check_str, (), {}, True),
            ("sig_figs", sig_figs, sfuncs.check_int, (), {"min_value": 1}, True),
            ("sci_lims", sci_lims, sfuncs.check_sci_lims, (), {}, True),
            (
                "integral_mode", integral_mode, sfuncs.check_one_of,
                ("relative", "absolute"),
            ),
            ("force_overwrite", force_overwrite, sfuncs.check_bool),
            ("fprint", fprint, sfuncs.check_bool),
        )
        sanity_check(("path", path, check_saveable_path, (fmt, force_overwrite)))

        indices = self._process_indices(indices)
        results = [self._results[i] for i in indices]
        writer = ResultWriter(
            self.expinfo,
            [result.get_params() for result in results],
            [result.get_errors() for result in results],
            description,
        )
        region_unit = "ppm" if self.hz_ppm_valid else "hz"

        titles = []
        for result in results:
            if result.get_region() is None:
                titles.append("Full signal")
            else:
                left, right = result.get_region(region_unit)[-1]
                titles.append(
                    f"{left:.3f} - {right:.3f} {region_unit}".replace("h", "H")
                )

        writer.write(
            path=path,
            fmt=fmt,
            titles=titles,
            parameters_sig_figs=sig_figs,
            parameters_sci_lims=sci_lims,
            integral_mode=integral_mode,
            force_overwrite=True,
            fprint=fprint,
            pdflatex_exe=pdflatex_exe,
        )

    def _plot_regions(
        self,
        indices: Iterable[int],
        region_unit: str,
    ) -> Tuple[Iterable[Iterable[int]], Iterable[Tuple[float, float]]]:
        regions = sorted(
            [
                (i, result.get_region(unit=region_unit)[-1])
                for i, result in enumerate(self.get_results())
                if i in indices
            ],
            key=lambda x: x[1][0],
            reverse=True,
        )

        # Merge overlapping/bordering regions
        merge_indices = []
        merge_regions = []
        for idx, region in regions:
            assigned = False
            for i, reg in enumerate(merge_regions):
                if max(region) >= min(reg):
                    merge_regions[i] = (max(reg), min(region))
                    assigned = True
                elif min(region) >= max(reg):
                    merge_regions[i] = (max(region), min(reg))
                    assigned = True

                if assigned:
                    merge_indices[i].append(idx)
                    break

            if not assigned:
                merge_indices.append([idx])
                merge_regions.append(region)

        return merge_indices, merge_regions

    def _configure_axes(
        self,
        fig: mpl.figure.Figure,
        axs: np.ndarray[mpl.axes.Axes],
        regions: Iterable[Tuple[float, float]],
        xaxis_ticks: Iterable[Tuple[int, Iterable[float]]],
        axes_left: float,
        axes_right: float,
        xaxis_label_height: float,
        region_unit: str,
    ) -> None:
        if axs.shape[0] > 1:
            for ax in axs[0]:
                ax.spines["bottom"].set_visible(False)
                ax.set_xticks([])
                ax.set_yticks([])
            for ax in axs[1]:
                ax.spines["top"].set_visible(False)
        for region, ax_col in zip(regions, axs.T):
            for ax in ax_col:
                ax.set_xlim(*region)

        if len(regions) > 1:
            for axs_col in axs[:, :-1]:
                for ax in axs_col:
                    ax.spines["right"].set_visible(False)
            for axs_col in axs[:, 1:]:
                for ax in axs_col:
                    ax.spines["left"].set_visible(False)

            break_kwargs = {
                "marker": [(-1, -3), (1, 3)],
                "markersize": 6,
                "linestyle": "none",
                "color": "k",
                "mec": "k",
                "mew": 1,
                "clip_on": False,
            }
            for ax in axs[0, :-1]:
                ax.plot([1], [1], transform=ax.transAxes, **break_kwargs)
            for ax in axs[0, 1:]:
                ax.plot([0], [1], transform=ax.transAxes, **break_kwargs)
            for ax in axs[-1, :-1]:
                ax.plot([1], [0], transform=ax.transAxes, **break_kwargs)
            for ax in axs[-1, 1:]:
                ax.plot([0], [0], transform=ax.transAxes, **break_kwargs)
                ax.set_yticks([])

        if xaxis_ticks is not None:
            for i, ticks in xaxis_ticks:
                axs[-1, i].set_xticks(ticks)

        label = self._axis_freq_labels(region_unit)[-1]

        fig.text(
            x=(axes_left + axes_right) / 2,
            y=xaxis_label_height,
            s=label,
            horizontalalignment="center",
        )

    def _region_check(self, region: Any, region_unit: str, name: str):
        return (
            name, region, sfuncs.check_region,
            (
                (self.sw(region_unit)[-1],),
                (self.offset(region_unit)[-1],)
            ),
            {}, True,
        )

    def _process_region(self, direct_region: Tuple[float, float]):
        return tuple(
            [
                tuple(direct_region) if i == self.dim - 1
                else None
                for i in range(self.dim)
            ]
        )

    @property
    def _full_region(self) -> Tuple[float, float]:
        return self.convert(
            self._process_region((0, self.data.shape[-1] - 1)),
            "idx->hz",
        )
